{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df11646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as dframe\n",
    "import cvxpy as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4737d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dic(feat_l_tr,feat_r_tr): #入力の配列は2次元配列である必要がある\n",
    "    feat_tr = np.concatenate([feat_l_tr, feat_r_tr],0)\n",
    "    return feat_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89096c5a-2cf3-4644-8021-ec385e239d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#各クラスの特徴ベクトルの配列の列数を格納した配列を引数にすればもう少し拡張性が上がる\n",
    "def SGRM(feat_tr,feat_tr_dic_1,feat_tr_dic_2,feat_tr_dic,feat_l_te,matrix_index,λ_1,λ_2):\n",
    "    #λ_1 = 0.01\n",
    "    #λ_2 = 0.01\n",
    "    answer = np.zeros(feat_l_te.shape[1])\n",
    "    #スパース性を格納する行列\n",
    "    SGRM_Cla = np.zeros((feat_tr_dic.shape[1], feat_l_te.shape[1]))\n",
    "    #leftクラスのみのスパース性を格納するための行列\n",
    "    SGRM_l_Cla = np.zeros((feat_tr_dic.shape[1], feat_l_te.shape[1]))\n",
    "    #rightクラスのみのスパース性を格納するための行列\n",
    "    SGRM_r_Cla = np.zeros((feat_tr_dic.shape[1], feat_l_te.shape[1]))\n",
    "    for i in range(feat_l_te.shape[1]):\n",
    "        u = cv.Variable((feat_tr_dic.shape[1],1)) #目的関数の次元\n",
    "        #SGRMの最適化問題を設定している\n",
    "        objective = cv.Minimize(0.5*(cv.norm(feat_tr_dic@u-feat_l_te[:,i,np.newaxis],2)**2)\n",
    "                                +λ_1*cv.norm(u[:,0],1)\n",
    "                                +λ_2*(cv.norm(u[0:feat_tr.shape[0],0],2)\n",
    "                                      +cv.norm(u[feat_tr.shape[0]:feat_tr_dic_1.shape[0],0],2)\n",
    "                                     +cv.norm(u[feat_tr_dic_1.shape[0]:feat_tr_dic_2.shape[0],0],2)\n",
    "                                     +cv.norm(u[feat_tr_dic_2.shape[0]:feat_tr_dic.shape[0],0],2)))\n",
    "                                     #+cv.norm(u[feat_tr_dic_3.shape[0]:feat_tr_dic.shape[0],0],2)))\n",
    "                                     #+cv.norm(u[feat_tr_dic_4.shape[0]:feat_tr_dic_5.shape[0],0],2)\n",
    "                                     #+cv.norm(u[feat_tr_dic_5.shape[0]:feat_tr_dic_6.shape[0],0],2)\n",
    "                                     #+cv.norm(u[feat_tr_dic_6.shape[0]:feat_tr_dic.shape[0],0],2)))\n",
    "        #constraints = [u == 0.5*(cv.norm(feat_tr_dic@u-feat_l_te[:,i,np.newaxis],2)**2)+λ_1*cv.norm(u[:,0],1)\n",
    "                       #+λ_2*(cv.norm(u[0:feat_tr.shape[0],0],2)\n",
    "                             #+cv.norm(u[feat_tr.shape[0]:feat_tr_dic_1.shape[0],0],2)\n",
    "                             #+cv.norm(u[feat_tr_dic_1.shape[0]:feat_tr_dic_2.shape[0],0],2)\n",
    "                             #+cv.norm(u[feat_tr_dic_2.shape[0]:feat_tr_dic_3.shape[0],0],2)\n",
    "                             #+cv.norm(u[feat_tr_dic_3.shape[0]:feat_tr_dic.shape[0],0],2))] \n",
    "                    \n",
    "        prob = cv.Problem(objective)\n",
    "        result = prob.solve()\n",
    "        #classVariableから値を取るためには.valueを付ける\n",
    "        SGRM_Cla[:,i] = np.squeeze(u.value)\n",
    "        #各クラスに関連する表現ベクトルの値を抜き出す\n",
    "        #lは仕切りの値\n",
    "        l = 0\n",
    "        j = 0\n",
    "        while j < matrix_index.shape[0]-1:\n",
    "            SGRM_l_Cla[l:l+matrix_index[j],i] = SGRM_Cla[l:l+matrix_index[j],i]     \n",
    "            l = l + matrix_index[j]\n",
    "            j = j + 1\n",
    "            SGRM_r_Cla[l:l+matrix_index[j],i] = SGRM_Cla[l:l+matrix_index[j],i]\n",
    "            l = l + matrix_index[j]\n",
    "            j = j + 1\n",
    "    #パラメータを使って擬似的に各クラスのテスト信号の特徴ベクトルを作成\n",
    "    dout_feat_l_te = np.zeros((feat_l_te.shape[0], feat_l_te.shape[1]))\n",
    "    dout_feat_r_te = np.zeros((feat_l_te.shape[0], feat_l_te.shape[1])) \n",
    "    for i in range(feat_l_te.shape[1]):\n",
    "        dout_feat_l_te[:,i] = feat_tr_dic@SGRM_l_Cla[:,i]\n",
    "    for i in range(feat_l_te.shape[1]):\n",
    "        dout_feat_r_te[:,i] = feat_tr_dic@SGRM_r_Cla[:,i]\n",
    "    #作成した擬似特徴ベクトルとの残差を求める\n",
    "    R_l =  np.zeros((feat_l_te.shape[0], feat_l_te.shape[1])) #残差を格納するための配列\n",
    "    R_r =  np.zeros((feat_l_te.shape[0], feat_l_te.shape[1]))  \n",
    "    for i in range(feat_l_te.shape[1]):\n",
    "        R_l[:,i] = feat_l_te[:,i]-dout_feat_l_te[:,i]\n",
    "        R_r[:,i] = feat_l_te[:,i]-dout_feat_r_te[:,i]\n",
    "        #残差を比べてクラスを割り当てる\n",
    "        if np.linalg.norm(R_l[:,i], ord=2) < np.linalg.norm(R_r[:,i], ord=2):\n",
    "            answer[i] = 1\n",
    "        elif np.linalg.norm(R_l[:,i], ord=2) > np.linalg.norm(R_r[:,i], ord=2):\n",
    "            answer[i] = 2\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faca1540-40c6-43e3-b2e9-fb36403bf8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGRM_test(filename1,filename2,filename3,filename4,C1_K1,C2_K1,C1_K2,C2_K2,C1_K3,C2_K3):\n",
    "    #対象被験者の特徴ベクトル(トレーニングデータ＆テストデータ)をMATLAB(自身で作成)から入手    feat_C1 = np.loadtxt(filename1,delimiter=\",\")\n",
    "    feat_C2 = np.loadtxt(filename2,delimiter=\",\")\n",
    "    feat_Test_C1 = np.loadtxt(filename3,delimiter=\",\")\n",
    "    feat_Test_C2 = np.loadtxt(filename4,delimiter=\",\")\n",
    "    #非対象被験者の特徴ベクトルをMATLABから入手\n",
    "    feat_C1_K1 = np.loadtxt(C1_K1,delimiter=\",\")\n",
    "    feat_C2_K1 = np.loadtxt(C2_K1,delimiter=\",\")\n",
    "    feat_C1_K2 = np.loadtxt(C1_K2,delimiter=\",\")\n",
    "    feat_C2_K2 = np.loadtxt(C1_K2,delimiter=\",\")\n",
    "    feat_C1_K3 = np.loadtxt(C1_K3,delimiter=\",\")\n",
    "    feat_C2_K3 = np.loadtxt(C1_K3,delimiter=\",\")\n",
    "\n",
    "    #対象被験者の各クラスのトレーニングデータから取得した特徴ベクトルを結合\n",
    "    feat_tr = Dic(feat_C1,feat_C2)\n",
    "    #非対象被験者の特徴ベクトルも同様の処理を行う\n",
    "    feat_tr_K1 = Dic(feat_C1_K1,feat_C2_K1)\n",
    "    feat_tr_K2 = Dic(feat_C1_K2,feat_C2_K2)\n",
    "    feat_tr_K3 = Dic(feat_C1_K3,feat_C2_K3)\n",
    "\n",
    "    #それぞれの特徴ベクトルをつなげる\n",
    "    #この時、2M×Nの行列にするために転置させる(2Mは特徴ベクトルの次元、Nはスパース表現を推定するために使用した特徴ベクトルの総数)\n",
    "    feat_tr_dic_1 = Dic(feat_tr,feat_tr_K1)\n",
    "    feat_tr_dic_2 = Dic(feat_tr_dic_1,feat_tr_K2)\n",
    "    feat_tr_dic = Dic(feat_tr_dic_2,feat_tr_K3).T\n",
    "    #feat_tr_dicはすべての特徴ベクトルをつなげたもの\n",
    "    #テストデータの特徴ベクトルも2Mが行になるように転置させる\n",
    "    feat_l_te = feat_Test_C1;\n",
    "    feat_r_te = feat_Test_C2;\n",
    "    feat_l_te = feat_l_te.T\n",
    "    feat_r_te = feat_r_te.T\n",
    "　　#各被験者の各クラスの特徴ベクトルの数を格納する(各クラスのみのスパース性を格納するための行列作成に使用)\n",
    "    matrix_index = np.array([feat_C1.shape[0],feat_C2.shape[0],feat_C1_K1.shape[0],feat_C2_K1.shape[0],feat_C1_K2.shape[0],feat_C2_K2.shape[0],\n",
    "                        feat_C1_K3.shape[0],feat_C2_K3.shape[0]])\n",
    "    Max = 0\n",
    "    #各ハイパーパラメーターでの正答率を格納\n",
    "    weight = np.array([])\n",
    "    #ハイパーパラメーターの値を0.01~0.1で0.01刻みで変更\n",
    "    for i in range(1,11):\n",
    "        λ_1 = i*0.01\n",
    "        print(i)\n",
    "        for j in range(1,11):\n",
    "            λ_2 = j*0.01\n",
    "            answer1 = SGRM(feat_tr,feat_tr_dic_1,feat_tr_dic_2,feat_tr_dic,feat_l_te,matrix_index,λ_1,λ_2)\n",
    "            answer2 = SGRM(feat_tr,feat_tr_dic_1,feat_tr_dic_2,feat_tr_dic,feat_r_te,matrix_index,λ_1,λ_2)\n",
    "            x1 = 0\n",
    "            x2 = 0\n",
    "            for i in range(answer1.shape[0]):\n",
    "                if answer1[i] == 1:\n",
    "                    x1 = x1 + 1\n",
    "                if answer2[i] == 2:\n",
    "                    x2 = x2 + 1\n",
    "            #全体での正答率と各クラスでの正答率を求める\n",
    "            temp = ((x1+x2)/(answer1.shape[0]+answer2.shape[0]))*100\n",
    "            temp1 = ((x1)/(answer1.shape[0]))*100\n",
    "            temp2 = ((x2)/(answer2.shape[0]))*100\n",
    "            weight_l = np.array([temp,λ_1,λ_2])\n",
    "            weight = np.append(weight,weight_l,axis=0)\n",
    "            if temp > Max:\n",
    "                Max = temp\n",
    "                \n",
    "    weight = weight.reshape([100, 3])                 \n",
    "    return Max,temp1,temp2,weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf3b542",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kota/opt/anaconda3/lib/python3.9/site-packages/cvxpy/problems/problem.py:1337: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[[ 51.25   0.   100.  ]\n",
      " [ 61.25  92.5   15.  ]\n",
      " [ 65.   100.    20.  ]\n",
      " [ 55.   100.     0.  ]\n",
      " [ 67.5   82.5   10.  ]]\n"
     ]
    }
   ],
   "source": [
    "#train=20,test=40で分類を行った結果\n",
    "probability = np.array([])\n",
    "temp,temp1,temp2,weight_1 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A01T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A01T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A01T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A01T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A02T_30.txt\",\"feat_2a_250Hz_30/feat_right_A02T_30.txt\",\"feat_2a_250Hz_30/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_2 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A02T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A02T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A02T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A02T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_3 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A03T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A03T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A03T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A03T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A02T_30.txt\",\"feat_2a_250Hz_30/feat_right_A02T_30.txt\",\"feat_2a_250Hz_30/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30/feat_right_A01T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_4 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A07T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A07T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A07T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A07T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_5 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A08T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A08T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A08T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A08T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "\n",
    "probability_1 = probability.reshape([5, 3])\n",
    "weight_1t = (weight_1[:,0]+weight_2[:,0]+weight_3[:,0]+weight_4[:,0]+weight_5[:,0])/5\n",
    "print(probability_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28ecfbec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#train=20,test=40で分類を行った結果\n",
    "probability = np.array([])\n",
    "temp,temp1,temp2,weight_1 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A01T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A01T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A01T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A01T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A02T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A02T_30.txt\",\"feat_2a_250Hz_30_2/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_2 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A02T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A02T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A02T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A02T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_3 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A03T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A03T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A03T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A03T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A02T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A02T_30.txt\",\"feat_2a_250Hz_30_2/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A01T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_4 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A07T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A07T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A07T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A07T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_5 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A08T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A08T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A08T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A08T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_2/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30_2/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_2/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "\n",
    "probability_2 = probability.reshape([5, 3])\n",
    "weight_2t = (weight_1[:,0]+weight_2[:,0]+weight_3[:,0]+weight_4[:,0]+weight_5[:,0])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03f6f676",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#train=20,test=40で分類を行った結果\n",
    "probability = np.array([])\n",
    "temp,temp1,temp2,weight_1 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A01T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A01T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A01T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A01T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A02T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A02T_30.txt\",\"feat_2a_250Hz_30_3/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_2 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A02T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A02T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A02T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A02T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_3 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A03T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A03T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A03T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A03T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A02T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A02T_30.txt\",\"feat_2a_250Hz_30_3/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A01T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_4 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A07T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A07T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A07T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A07T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "temp,temp1,temp2,weight_5 = SGRM_test(\"feat_2a_250Hz_20_test/feat_left_A08T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_right_A08T_20_K0.txt\",\"feat_2a_250Hz_20_test/feat_test_left_A08T_20.txt\",\"feat_2a_250Hz_20_test/feat_test_right_A08T_20.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A03T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A03T_30.txt\"\n",
    "                           ,\"feat_2a_250Hz_30_3/feat_left_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A01T_30.txt\",\"feat_2a_250Hz_30_3/feat_left_A09T_30.txt\",\"feat_2a_250Hz_30_3/feat_right_A09T_30.txt\")\n",
    "temp_l = np.array([temp,temp1,temp2])\n",
    "probability = np.append(probability,temp_l,axis=0)\n",
    "\n",
    "probability_3 = probability.reshape([5, 3])\n",
    "weight_3t = (weight_1[:,0]+weight_2[:,0]+weight_3[:,0]+weight_4[:,0]+weight_5[:,0])/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b4ab2d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.333333333333336\n",
      "[0.01 0.06]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.03</th>\n",
       "      <th>0.04</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.06</th>\n",
       "      <th>0.07</th>\n",
       "      <th>0.08</th>\n",
       "      <th>0.09</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>53.7</td>\n",
       "      <td>54.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>53.9</td>\n",
       "      <td>54.1</td>\n",
       "      <td>55.3</td>\n",
       "      <td>54.9</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.9</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>52.1</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.8</td>\n",
       "      <td>53.8</td>\n",
       "      <td>53.8</td>\n",
       "      <td>54.2</td>\n",
       "      <td>53.2</td>\n",
       "      <td>53.8</td>\n",
       "      <td>54.8</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>52.4</td>\n",
       "      <td>52.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>53.8</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.3</td>\n",
       "      <td>53.7</td>\n",
       "      <td>54.2</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>52.2</td>\n",
       "      <td>52.1</td>\n",
       "      <td>53.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.7</td>\n",
       "      <td>53.7</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>52.1</td>\n",
       "      <td>52.7</td>\n",
       "      <td>52.8</td>\n",
       "      <td>53.8</td>\n",
       "      <td>54.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.8</td>\n",
       "      <td>53.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>52.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>52.4</td>\n",
       "      <td>53.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>54.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.07</th>\n",
       "      <td>52.2</td>\n",
       "      <td>52.2</td>\n",
       "      <td>52.9</td>\n",
       "      <td>52.5</td>\n",
       "      <td>53.7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.7</td>\n",
       "      <td>53.9</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>53.2</td>\n",
       "      <td>51.9</td>\n",
       "      <td>52.5</td>\n",
       "      <td>52.2</td>\n",
       "      <td>53.4</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.9</td>\n",
       "      <td>53.8</td>\n",
       "      <td>53.4</td>\n",
       "      <td>53.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>53.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>52.5</td>\n",
       "      <td>52.7</td>\n",
       "      <td>52.6</td>\n",
       "      <td>53.3</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.7</td>\n",
       "      <td>53.8</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>52.6</td>\n",
       "      <td>51.9</td>\n",
       "      <td>52.6</td>\n",
       "      <td>52.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>53.1</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.5</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.01  0.02  0.03  0.04  0.05  0.06  0.07  0.08  0.09  0.1\n",
       "0.01  53.7  54.2  54.2  53.9  54.1  55.3  54.9  53.6  53.9 52.5\n",
       "0.02  52.1  53.6  53.8  53.8  53.8  54.2  53.2  53.8  54.8 54.2\n",
       "0.03  52.4  52.8  54.0  54.2  53.8  53.5  53.3  53.7  54.2 53.8\n",
       "0.04  52.2  52.1  53.1  54.0  53.9  53.5  53.6  53.7  53.7 53.6\n",
       "0.05  52.1  52.7  52.8  53.8  54.2  54.0  54.0  53.6  53.8 53.9\n",
       "0.06  52.2  52.6  52.4  53.1  54.1  54.2  54.2  54.0  54.0 53.8\n",
       "0.07  52.2  52.2  52.9  52.5  53.7  54.0  53.7  53.9  53.5 53.6\n",
       "0.08  53.2  51.9  52.5  52.2  53.4  53.5  53.9  53.8  53.4 53.5\n",
       "0.09  53.0  51.8  52.5  52.7  52.6  53.3  53.5  53.7  53.8 53.6\n",
       "0.1   52.6  51.9  52.6  52.5  52.5  53.1  53.6  53.5  53.5 53.7"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_average_250Hz = (probability_1+probability_2+probability_3)/3\n",
    "weight_result = (weight_1t+weight_2t+weight_3t)/3\n",
    "max_index = np.argmax(weight_result)\n",
    "print(weight_result[max_index])\n",
    "print(weight_1[max_index,1:3])\n",
    "weight_result = weight_result.reshape([10,10])\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "feature1 = [\"0.01\",\"0.02\",\"0.03\",\"0.04\",\"0.05\",\"0.06\",\"0.07\",\"0.08\",\"0.09\",\"0.1\"]\n",
    "name1 = [\"0.01\",\"0.02\",\"0.03\",\"0.04\",\"0.05\",\"0.06\",\"0.07\",\"0.08\",\"0.09\",\"0.1\"]\n",
    "df = pd.DataFrame(weight_result,feature1,name1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57497e-6d8b-4131-9c19-96c576b13f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
